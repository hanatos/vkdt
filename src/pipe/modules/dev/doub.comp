#version 460
#extension GL_GOOGLE_include_directive    : enable
#extension GL_EXT_nonuniform_qualifier    : enable

#include "shared.glsl"

layout(local_size_x = DT_LOCAL_SIZE_X, local_size_y = DT_LOCAL_SIZE_Y, local_size_z = 1) in;

layout(std140, set = 0, binding = 1) uniform params_t
{
  float white;
} params;

layout(push_constant, std140) uniform push_t
{
  vec4 wb;
  uint filters;
} push;

layout( // input uint16 buffer rggb
    set = 1, binding = 0
) uniform sampler2D img_in;

layout( // input f16 buffer rgb
    set = 1, binding = 1
) uniform sampler2D img_coarse;

layout( // output f16 buffer rggb
    set = 1, binding = 2
) uniform writeonly image2D img_out;

// upsample back to mosaic. this is either 3x3 or 2x2, depending on filters.
// runs on coarse resolution.
// our goal is to do one scale of decimated wavelet denoising, while keeping
// clipped pixels clipped (these will be copied straight to the output)
void
main()
{
  ivec2 ipos = ivec2(gl_GlobalInvocationID);
  if(any(greaterThanEqual(ipos, imageSize(img_out)))) return;

  vec3 upsm = texelFetch(img_coarse, ipos, 0).rgb;
  const float white = params.white;

  if(push.filters == 9)
  {
    // swap red and blue channels according to sensor layout
    if(((ipos.x + ipos.y) & 1) == 0)
      upsm.rgb = upsm.bgr;
    // get original input texels
    float c0 = texelFetch(img_in, 3*ipos, 0).r;
    float c1 = texelFetch(img_in, 3*ipos+ivec2(0,1), 0).r;
    float c2 = texelFetch(img_in, 3*ipos+ivec2(0,2), 0).r;
    float c3 = texelFetch(img_in, 3*ipos+ivec2(1,0), 0).r;
    float c4 = texelFetch(img_in, 3*ipos+ivec2(1,1), 0).r;
    float c5 = texelFetch(img_in, 3*ipos+ivec2(1,2), 0).r;
    float c6 = texelFetch(img_in, 3*ipos+ivec2(2,0), 0).r;
    float c7 = texelFetch(img_in, 3*ipos+ivec2(2,1), 0).r;
    float c8 = texelFetch(img_in, 3*ipos+ivec2(2,2), 0).r;

    // do wavelet shrinkage with these channels.
    // make sure to keep clipped (>= white)!
#define SHRINK(A, B)\
    if(A < white) { \
      float wav = A - B;\
      A = B + sign(wav) * max(0.0, abs(wav - T));\
    }

    // TODO: colour channel threshold
    float T = 1.0;// XXX
    SHRINK(c1, upsm.r)
    SHRINK(c7, upsm.r)
    SHRINK(c3, upsm.b)
    SHRINK(c5, upsm.b)

    // TODO: T = green threshold
    SHRINK(c0, upsm.g)
    SHRINK(c2, upsm.g)
    SHRINK(c4, upsm.g)
    SHRINK(c6, upsm.g)
    SHRINK(c8, upsm.g)
#undef SHRINK
    // TODO: noise model needs adjustment for filters

#if 0 // this is hilite code:
    float minr = min(c1, c7);
    float minb = min(c3, c5);
    float ming = min(min(min(c0, c2), c4), min(c6, c8));
    float scale = 1.0f;

    // determine by blurry image, without wb:
    if     (upsm.r < upsm.g && upsm.r < upsm.b)
      scale = minr/max(0.001, upsm.r);
    else if(upsm.b < upsm.g && upsm.b < upsm.r)
      scale = minb/max(0.001, upsm.b);
    else if(upsm.g < upsm.r && upsm.g < upsm.b)
      scale = ming /max(0.001,  upsm.g);

    float maxr = max(c1, c7);
    float maxb = max(c3, c5);
    float maxg = max(max(max(c0, c2), c4), max(c6, c8));
    if(maxr >= white || maxb >= white || maxg >= white)
    {
      c1 = upsm.r * scale;
      c7 = upsm.r * scale;
      c3 = upsm.b * scale;
      c5 = upsm.b * scale;

      c0 = upsm.g * scale;
      c2 = upsm.g * scale;
      c4 = upsm.g * scale;
      c6 = upsm.g * scale;
      c8 = upsm.g * scale;
    }
#endif

    imageStore(img_out, 3*ipos,            vec4(vec3(c0), 1));
    imageStore(img_out, 3*ipos+ivec2(0,1), vec4(vec3(c1), 1));
    imageStore(img_out, 3*ipos+ivec2(0,2), vec4(vec3(c2), 1));
    imageStore(img_out, 3*ipos+ivec2(1,0), vec4(vec3(c3), 1));
    imageStore(img_out, 3*ipos+ivec2(1,1), vec4(vec3(c4), 1));
    imageStore(img_out, 3*ipos+ivec2(1,2), vec4(vec3(c5), 1));
    imageStore(img_out, 3*ipos+ivec2(2,0), vec4(vec3(c6), 1));
    imageStore(img_out, 3*ipos+ivec2(2,1), vec4(vec3(c7), 1));
    imageStore(img_out, 3*ipos+ivec2(2,2), vec4(vec3(c8), 1));
  }
  else
  {
    // reads : w z -> r g
    //         x y    g b
    vec4 c = textureGather(img_in, 2*(ipos+.5)/vec2(textureSize(img_in, 0)), 0);
    float ming = min(c.x, c.z);
    float scale;

    // find by blurry image
    if     (upsm.r < upsm.g && upsm.r < upsm.b)  scale = c.w /max(0.0001, upsm.r);
    else if(upsm.g < upsm.r && upsm.g < upsm.b)  scale = ming/max(0.0001, upsm.g);
    else /*(upsm.b < upsm.g && upsm.b < upsm.r)*/scale = c.y /max(0.0001, upsm.b);

    if(c.x >= white ||
       c.y >= white ||
       c.z >= white ||
       c.w >= white)
      c = scale * upsm.gbgr;
    imageStore(img_out, 2*ipos,            vec4(c.w));
    imageStore(img_out, 2*ipos+ivec2(1,0), vec4(c.z));
    imageStore(img_out, 2*ipos+ivec2(0,1), vec4(c.x));
    imageStore(img_out, 2*ipos+ivec2(1,1), vec4(c.y));
  }
}

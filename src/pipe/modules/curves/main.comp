#version 460
#extension GL_GOOGLE_include_directive    : enable
#extension GL_EXT_nonuniform_qualifier    : enable
#include "shared.glsl"
layout(local_size_x = DT_LOCAL_SIZE_X, local_size_y = DT_LOCAL_SIZE_Y, local_size_z = 1) in;
layout(std140, set = 0, binding = 1) uniform params_t
{
  vec4 abcdr[8];
  vec4 abcdg[8];
  vec4 abcdb[8];
  vec4 xr0, xr1;
  vec4 xg0, xg1;
  vec4 xb0, xb1;
  vec4 yr0, yr1;
  vec4 yg0, yg1;
  vec4 yb0, yb1;
  int  cntr, cntg, cntb;
  int  sel;
  int  mode;
  int  chan;
  int  ychchan;
  int  edit;
  int  pad0, pad1;
  float ddr0, ddrn;
  float ddg0, ddgn;
  float ddb0, ddbn;
  vec4 vtx1[3], vtx2[3], vtx3[3], vtx4[3], vtx5[3], vtx6[3], vtx7[3], vtx8[3];
  vec4 abcd1[6], abcd2[6], abcd3[6], abcd4[6], abcd5[6], abcd6[6], abcd7[6], abcd8[6];
} params;
layout(set = 1, binding = 0) uniform sampler2D img_in;
layout(set = 1, binding = 1) uniform sampler2D img_a;
layout(set = 1, binding = 2) uniform sampler2D img_b; // blurred ab channels for noise free chroma/hue
layout(set = 1, binding = 3) uniform writeonly image2D img_out;
#include "eq.glsl"
#include "spline.glsl"

void main()
{
  ivec2 ipos = ivec2(gl_GlobalInvocationID);
  if(any(greaterThanEqual(ipos, imageSize(img_out)))) return;
  vec3 rgb = texelFetch(img_in, ipos, 0).rgb;
  float ddx;
  if(params.mode < 2)
  { // rgb or luminance
    rgb.r = curve_eval(params.mode == 1 ? params.chan : 0, rgb.r, ddx);
    rgb.g = curve_eval(params.mode == 1 ? params.chan : 1, rgb.g, ddx);
    rgb.b = curve_eval(params.mode == 1 ? params.chan : 2, rgb.b, ddx);
  }
  else
  { // ych
    // convert rec2020 rgb to yuv and lch from there
    // vec3 ychi = rgb2ych(rgb);
    vec2 ab = vec2(texelFetch(img_a, ipos, 0).r, texelFetch(img_b, ipos, 0).r);
    vec3 oklab = rec2020_to_oklab(rgb);
    // css oklab sets 100% saturation at 0.4
    oklab.yz /= 0.4*max(0.01, oklab.x); // divide L for "hunt effect"
    vec3 ychi = vec3(oklab.x, length(oklab.yz), fract(1.0 + atan(oklab.z, oklab.y)/(2.0*M_PI)));

    // now we move ych through the 3x3 curve system (ych x ych):
    // step 1: apply curves to the diagonal (y/y, c/c, h/h, these are diagonal lines or splines):
    vec3 ycho = vec3(
        curve_eval(0, ychi.r, ddx),
        ychi.g,
        ychi.b);

    // only use blurred input for relative stuff
    float guided_a = texelFetch(img_a, ipos, 0).r;
    float guided_b = texelFetch(img_b, ipos, 0).r;
    oklab.yz = vec2(guided_a, guided_b);
    oklab.yz /= 0.4*max(0.01, oklab.x); // divide L for "hunt effect"
    ychi = vec3(oklab.x, length(oklab.yz), fract(1.0 + atan(oklab.z, oklab.y)/(2.0*M_PI)));

    ycho.g += curve_horiz(1, ychi.g, ddx); // c/c
    ycho.b += curve_horiz(2, ychi.b, ddx); // h/h

    // step 2: the off-diagonals: apply the remaining two dependencies. these are relative,
    // i.e. start from flat lines in the graphs. also these aren't splines but cosine interpolation (less ringing)
    ycho.r += curve_horiz(3, ychi.g, ddx); // y/c
    ycho.g += curve_horiz(4, ychi.r, ddx); // c/y
    ycho.b += curve_horiz(5, ychi.r, ddx); // h/y
    ycho.r += curve_horiz(6, ychi.b, ddx); // y/h
    ycho.g += curve_horiz(7, ychi.b, ddx); // c/h
    ycho.b += curve_horiz(8, ychi.g, ddx); // h/c

    ycho.g = max(ycho.g, 0.0); // no negative chroma, does weird shit

    // convert back: ych -> YCbCr -> rgb (rec2020)
    // rgb = ych2rgb(ycho);
    rgb = oklsh_to_rec2020(ycho);
  }
  imageStore(img_out, ipos, vec4(rgb, 1));
}
